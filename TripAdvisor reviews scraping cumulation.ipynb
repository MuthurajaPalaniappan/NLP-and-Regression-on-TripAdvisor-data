{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from bs4 import SoupStrainer\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.error, urllib.parse\n",
    "import time\n",
    "from urllib.request import FancyURLopener  # This is library that helps us create the headless browser\n",
    "from random import choice #This library helps pick a random item from a list\n",
    "import re\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "P:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: MyOpener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16',\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'\n",
    "]\n",
    "\n",
    "class MyOpener(FancyURLopener, object):\n",
    "    version = choice(user_agents)\n",
    "myopener = MyOpener()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of restaurant urls from csv file\n",
    "url_list = pd.read_csv('Restaurant_Links.csv')\n",
    "#print(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening restautrant number: 1\n",
      "Opening restautrant number: 2\n",
      "Opening restautrant number: 3\n",
      "Opening restautrant number: 4\n",
      "Opening restautrant number: 5\n",
      "Opening restautrant number: 6\n",
      "Opening restautrant number: 7\n",
      "Opening restautrant number: 8\n",
      "Opening restautrant number: 9\n",
      "Opening restautrant number: 10\n",
      "Opening restautrant number: 11\n",
      "Opening restautrant number: 12\n",
      "Opening restautrant number: 13\n",
      "Opening restautrant number: 14\n",
      "Opening restautrant number: 15\n",
      "Opening restautrant number: 16\n",
      "Opening restautrant number: 17\n",
      "Opening restautrant number: 18\n",
      "Opening restautrant number: 19\n",
      "Opening restautrant number: 20\n",
      "Opening restautrant number: 21\n",
      "Opening restautrant number: 22\n",
      "Opening restautrant number: 23\n",
      "Opening restautrant number: 24\n",
      "Opening restautrant number: 25\n",
      "Opening restautrant number: 26\n",
      "Opening restautrant number: 27\n",
      "Opening restautrant number: 28\n",
      "Opening restautrant number: 29\n",
      "Error\n",
      "Opening restautrant number: 30\n",
      "Opening restautrant number: 31\n",
      "Opening restautrant number: 32\n",
      "Opening restautrant number: 33\n",
      "Opening restautrant number: 34\n",
      "Opening restautrant number: 35\n",
      "Opening restautrant number: 36\n",
      "Error\n",
      "Opening restautrant number: 37\n",
      "Opening restautrant number: 38\n",
      "Opening restautrant number: 39\n",
      "Opening restautrant number: 40\n",
      "Opening restautrant number: 41\n",
      "Opening restautrant number: 42\n",
      "Opening restautrant number: 43\n",
      "Opening restautrant number: 44\n",
      "Opening restautrant number: 45\n",
      "Opening restautrant number: 46\n",
      "Opening restautrant number: 47\n",
      "Opening restautrant number: 48\n",
      "Opening restautrant number: 49\n",
      "Opening restautrant number: 50\n",
      "Opening restautrant number: 51\n",
      "Error\n",
      "Opening restautrant number: 52\n",
      "Opening restautrant number: 53\n",
      "Opening restautrant number: 54\n",
      "Opening restautrant number: 55\n",
      "Error\n",
      "Opening restautrant number: 56\n",
      "Opening restautrant number: 57\n",
      "Opening restautrant number: 58\n",
      "Opening restautrant number: 59\n",
      "Opening restautrant number: 60\n",
      "Opening restautrant number: 61\n",
      "Opening restautrant number: 62\n",
      "Opening restautrant number: 63\n",
      "Opening restautrant number: 64\n",
      "Opening restautrant number: 65\n",
      "Opening restautrant number: 66\n",
      "Opening restautrant number: 67\n",
      "Opening restautrant number: 68\n",
      "Opening restautrant number: 69\n",
      "Opening restautrant number: 70\n",
      "Opening restautrant number: 71\n",
      "Opening restautrant number: 72\n",
      "Opening restautrant number: 73\n",
      "Error\n",
      "Opening restautrant number: 74\n",
      "Opening restautrant number: 75\n",
      "Opening restautrant number: 76\n",
      "Opening restautrant number: 77\n",
      "Opening restautrant number: 78\n",
      "Opening restautrant number: 79\n",
      "Opening restautrant number: 80\n",
      "Opening restautrant number: 81\n",
      "Opening restautrant number: 82\n",
      "Opening restautrant number: 83\n",
      "Opening restautrant number: 84\n",
      "Opening restautrant number: 85\n",
      "Error\n",
      "Opening restautrant number: 86\n",
      "Opening restautrant number: 87\n",
      "Opening restautrant number: 88\n",
      "Error\n",
      "Opening restautrant number: 89\n",
      "Opening restautrant number: 90\n",
      "Error\n",
      "Opening restautrant number: 91\n",
      "Error\n",
      "Opening restautrant number: 92\n",
      "Opening restautrant number: 93\n",
      "Opening restautrant number: 94\n",
      "Opening restautrant number: 95\n",
      "Opening restautrant number: 96\n",
      "Opening restautrant number: 97\n",
      "Opening restautrant number: 98\n",
      "Opening restautrant number: 99\n",
      "Error\n",
      "Opening restautrant number: 100\n",
      "Error\n",
      "Opening restautrant number: 101\n",
      "Opening restautrant number: 102\n",
      "Opening restautrant number: 103\n",
      "Opening restautrant number: 104\n",
      "Opening restautrant number: 105\n",
      "Opening restautrant number: 106\n",
      "Opening restautrant number: 107\n",
      "Opening restautrant number: 108\n",
      "Opening restautrant number: 109\n",
      "Opening restautrant number: 110\n",
      "Opening restautrant number: 111\n",
      "Opening restautrant number: 112\n",
      "Opening restautrant number: 113\n",
      "Opening restautrant number: 114\n",
      "Opening restautrant number: 115\n",
      "Opening restautrant number: 116\n",
      "Opening restautrant number: 117\n",
      "Opening restautrant number: 118\n",
      "Error\n",
      "Opening restautrant number: 119\n",
      "Opening restautrant number: 120\n",
      "Opening restautrant number: 121\n",
      "Opening restautrant number: 122\n",
      "Opening restautrant number: 123\n",
      "Opening restautrant number: 124\n",
      "Opening restautrant number: 125\n",
      "Opening restautrant number: 126\n",
      "Opening restautrant number: 127\n",
      "Opening restautrant number: 128\n",
      "Opening restautrant number: 129\n",
      "Opening restautrant number: 130\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "error_urls = []\n",
    "restaurant_name = []\n",
    "restaurant_rating = []\n",
    "restaurant_rating_count = []\n",
    "restaurant_food_rating = []\n",
    "restaurant_service_rating = []\n",
    "restaurant_value_rating = []\n",
    "large_review_restaurant_link = []\n",
    "large_review_review_no = []\n",
    "for url in url_list['Restaurant_names']:\n",
    "    try:\n",
    "        counter+=1\n",
    "        print('Opening restautrant number:', counter)\n",
    "        page=myopener.open(url)\n",
    "        html = page.read().decode('utf-8')\n",
    "\n",
    "        #BeautifulSoup takes a string object and parse out the document structure\n",
    "        # and turn it into a BeautifulSoup object.\n",
    "        soup = BeautifulSoup(html, \"html5lib\")\n",
    "\n",
    "        # From the inspecting of the elements we can see that all the restaturant names, overall ratings, number of reviews are\n",
    "        # embedded in <div id = \"taplc_location_detail_header_restaurants_0\">\n",
    "        header = soup.find_all('div', attrs={\"id\": \"taplc_location_detail_header_restaurants_0\"})\n",
    "\n",
    "        # Parse the restaurant name embedded in <h1 class = \"heading_title\">\n",
    "        restaurant = header[0].find('h1', attrs={\"class\": \"heading_title\"})\n",
    "        restaurant_name.append(restaurant.string)\n",
    "\n",
    "        #Parse ratings\n",
    "        rating = header[0].find('span', {\"property\": \"ratingValue\"})['content']\n",
    "        restaurant_rating.append(rating)\n",
    "\n",
    "        #Parse number of ratings\n",
    "        count = header[0].find('span', {\"property\": \"count\"}).getText()\n",
    "        restaurant_rating_count.append(count)\n",
    "\n",
    "\n",
    "        # From the inspecting of the elements we can see that the food, value, service and atmosphere ratings are\n",
    "        # embedded in <div id = \"taplc_location_detail_header_restaurants_0\">\n",
    "        middle_section = soup.find_all('div', attrs={\"class\": \"ui_columns is-multiline questionRatings\"})\n",
    "\n",
    "        keys = []\n",
    "        classes = [value for element in middle_section[0].find_all(class_=\"ui_bubble_rating\") for value in element[\"class\"]]\n",
    "        for mid_sec_inner in middle_section[0].find_all('span', attrs={\"class\": \"text\"}):\n",
    "            keys.append(mid_sec_inner.getText())\n",
    "        separate_ratings = []\n",
    "        for value in classes:\n",
    "            try:\n",
    "                separate_ratings.append(float(value[value.find('bubble_')+7:])/10)\n",
    "            except:\n",
    "                pass\n",
    "        restaurant_food_rating.append(separate_ratings[0])\n",
    "        restaurant_service_rating.append(separate_ratings[1])\n",
    "        restaurant_value_rating.append(separate_ratings[2])\n",
    "\n",
    "        Reviewer_ID = []\n",
    "        Review_title = []\n",
    "        Review_date = []\n",
    "        Reviews = []\n",
    "        Overall_rating = []\n",
    "\n",
    "        last_page=False\n",
    "\n",
    "        while last_page == False:\n",
    "\n",
    "            for review in soup.find_all(\"div\", class_ = \"review-container\"):\n",
    "                uid_str = review.find_all(\"div\", class_='memberOverlayLink')\n",
    "                if (len(uid_str) == 0):\n",
    "                    Reviewer_ID.append(review.find_all(\"img\", class_='basicImg')[0].get('data-mediaid'))\n",
    "        #         print(uid_str)\n",
    "                else:\n",
    "                    Reviewer_ID.append(uid_str[0].get('id'))\n",
    "\n",
    "                overall_rating = float(review.find_all(\"span\", class_=re.compile(\"^ui_bubble_rating bubble_\"))[0].attrs[\"class\"][1][-2:])/10\n",
    "        #         print(overall_rating)\n",
    "                Overall_rating.append(overall_rating)\n",
    "\n",
    "                rating_title = review.find_all(\"span\", class_=\"noQuotes\")[0].string\n",
    "        #         print(rating_title)\n",
    "                Review_title.append('\"' + rating_title + '\"')\n",
    "\n",
    "                rating_date = review.find_all(\"span\", {\"class\": \"ratingDate\"})[0]['title']\n",
    "        #         print(rating_date)\n",
    "                Review_date.append(rating_date)\n",
    "\n",
    "                large_review = review.find_all('span', class_ = 'taLnk ulBlueLinks')\n",
    "                if (len(large_review)):\n",
    "\n",
    "                    #### Modify code here if you want to get full comments here itself\n",
    "\n",
    "                    large_review_restaurant_link.append(url)\n",
    "                    large_review_review_no.append(review.get('data-reviewid'))\n",
    "\n",
    "                rating_content = review.find_all(\"p\", class_=\"partial_entry\")[0].contents[0]\n",
    "                rating_content = re.sub('\\n', ' ', rating_content)\n",
    "        #         print(rating_content)\n",
    "                Reviews.append('\"' + rating_content + '\"')\n",
    "\n",
    "\n",
    "            try:\n",
    "                # Open next page reviews\n",
    "                pagination = soup.find_all(\"div\", class_ = \"prw_rup prw_common_north_star_pagination \")\n",
    "                link = \"https://www.tripadvisor.com\"+pagination[0].find_all('a', {\"class\": \"nav next taLnk ui_button primary\"})[0]['href']\n",
    "                page=myopener.open(link)\n",
    "                html = page.read().decode('utf-8') #loading each reviews page\n",
    "                soup = BeautifulSoup(html, \"html5lib\")\n",
    "\n",
    "            except:\n",
    "                last_page=True\n",
    "\n",
    "        # Writing it to csv file\n",
    "        rest_reviews = pd.DataFrame({\n",
    "            'Overall_rating': Overall_rating,\n",
    "            'Reviewer_ID': Reviewer_ID,\n",
    "            'Review_title': Review_title,\n",
    "            'Review_date': Review_date,\n",
    "            'Reviews':Reviews\n",
    "        })\n",
    "        rest_reviews.to_csv('reviews_folder/' + str(counter)+'. ' +restaurant.string + '_reviews.csv', sep='|', encoding='utf-8', index=False)\n",
    "        \n",
    "    except:\n",
    "        print('Error')\n",
    "        error_urls.append(url)\n",
    "error_urls.to_csv('error_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(url)\n",
    "#Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviewer_ID\n",
    "'reviews_folder/' + str(counter) +restaurant.string + '_reviews.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
